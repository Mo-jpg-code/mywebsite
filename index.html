<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Self-Learning Jump AI</title>
    <style>
        body { font-family: sans-serif; display: flex; flex-direction: column; align-items: center; background-color: #f0f0f0; margin-top: 20px; }
        .container { display: flex; flex-direction: row; align-items: flex-start; gap: 20px; }
        canvas { border: 1px solid black; background-color: #e0e0e0; }
        #gameCanvas { background-color: #d0e0f0; }
        #aiVisionCanvas { background-color: #f0f0d0; }
        .stats { border: 1px solid #ccc; padding: 10px; background-color: white; min-width: 200px; }
        .stats p { margin: 5px 0; }
        h1, h2 { text-align: center; }
    </style>
</head>
<body>
    <h1>Self-Learning Jump AI</h1>

    <div class="container">
        <div>
            <h2>Game World</h2>
            <canvas id="gameCanvas" width="600" height="300"></canvas>
        </div>
        <div>
            <h2>AI "Vision" (Discretized State)</h2>
            <canvas id="aiVisionCanvas" width="150" height="150"></canvas>
            <div class="stats">
                <h2>Stats</h2>
                <p>Episode: <span id="episode">0</span></p>
                <p>Cookies (Successes): <span id="cookies">0</span></p>
                <p>Punishments (Fails): <span id="punishments">0</span></p>
                <p>Epsilon (Exploration): <span id="epsilon">1.00</span></p>
                <p>Last Action: <span id="lastAction">-</span></p>
                <p>Learning Rate (Alpha): <span id="alpha">0.1</span></p>
                <p>Discount (Gamma): <span id="gamma">0.9</span></p>
            </div>
        </div>
    </div>

    <script>
        // --- Game Elements ---
        const gameCanvas = document.getElementById('gameCanvas');
        const gameCtx = gameCanvas.getContext('2d');
        const aiVisionCanvas = document.getElementById('aiVisionCanvas');
        const aiVisionCtx = aiVisionCanvas.getContext('2d');

        // --- DOM Elements for Stats ---
        const episodeEl = document.getElementById('episode');
        const cookiesEl = document.getElementById('cookies');
        const punishmentsEl = document.getElementById('punishments');
        const epsilonEl = document.getElementById('epsilon');
        const lastActionEl = document.getElementById('lastAction');
        const alphaEl = document.getElementById('alpha');
        const gammaEl = document.getElementById('gamma');

        // --- Game Constants ---
        const GRAVITY = 0.5;
        const PLAYER_JUMP_FORCE = -10; // Negative is up
        const PLAYER_MOVE_SPEED = 3;
        const GROUND_Y = gameCanvas.height - 20;
        const OBSTACLE_WIDTH = 30;
        const OBSTACLE_HEIGHT = 60;
        const GOAL_LINE_X = 500;
        const GOAL_LINE_WIDTH = 5;
        const MAX_STEPS_PER_EPISODE = 500; // To prevent infinite loops if stuck

        // --- Player Object ---
        let player = {
            x: 50,
            y: GROUND_Y - 30, // Start on ground
            width: 20,
            height: 30,
            vy: 0, // Vertical velocity
            onGround: true
        };

        // --- Obstacle Object ---
        let obstacle = {
            x: 300,
            y: GROUND_Y - OBSTACLE_HEIGHT,
            width: OBSTACLE_WIDTH,
            height: OBSTACLE_HEIGHT
        };
        
        // --- AI Q-Learning Parameters ---
        let qTable = {}; // { "state_string": [q_action0, q_action1, q_action2, q_action3] }
        const LEARNING_RATE = 0.1; // Alpha
        const DISCOUNT_FACTOR = 0.9; // Gamma
        let epsilon = 1.0; // Exploration rate
        const EPSILON_DECAY = 0.999; // Slower decay for more exploration
        const MIN_EPSILON = 0.01;

        // Actions: 0: Do Nothing, 1: Move Forward, 2: Jump, 3: Move Forward + Jump
        const ACTIONS = [
            { move: false, jump: false, name: "Nothing" },
            { move: true,  jump: false, name: "Move" },
            { move: false, jump: true,  name: "Jump" },
            { move: true,  jump: true,  name: "Move+Jump" }
        ];

        // --- Game State Variables ---
        let cookies = 0;
        let punishments = 0;
        let episodeCount = 0;
        let currentSteps = 0;

        // --- Helper: Get Discretized State ---
        // This function converts the continuous game state into a discrete representation
        // that the AI can use as a key in the Q-table.
        // We discretize distance to obstacle, player's height relative to obstacle top, and if on ground.
        function getDiscretizedState() {
            const distToObstacleX = Math.floor((obstacle.x - (player.x + player.width)) / 40); // Buckets of 40px
            const playerTopY = player.y;
            const obstacleTopY = obstacle.y;
            const heightDiffToObstacleTop = Math.floor((playerTopY - obstacleTopY) / 30); // Buckets of 30px
            const playerIsBeforeObstacle = (player.x + player.width) < obstacle.x;
            const playerIsOverObstacle = (player.x < obstacle.x + obstacle.width) && ((player.x + player.width) > obstacle.x);
            const playerHasPassedObstacle = player.x > (obstacle.x + obstacle.width);

            // Simplified AI vision state:
            // 0: Far before obstacle
            // 1: Near before obstacle
            // 2: Directly under/level with obstacle (horizontally)
            // 3: Past obstacle
            let horizontalPosCategory;
            if (distToObstacleX > 2) horizontalPosCategory = 0; // Far
            else if (distToObstacleX >= 0 && playerIsBeforeObstacle) horizontalPosCategory = 1; // Near
            else if (playerIsOverObstacle) horizontalPosCategory = 2; // Under/Over
            else horizontalPosCategory = 3; // Past


            // Height categories relative to obstacle top:
            // 0: Significantly below obstacle top
            // 1: Near or at obstacle top
            // 2: Significantly above obstacle top
            let verticalPosCategory;
            if (heightDiffToObstacleTop > 1) verticalPosCategory = 0; // Below
            else if (heightDiffToObstacleTop >= -1) verticalPosCategory = 1; // Near/Level
            else verticalPosCategory = 2; // Above
            
            // Is player approaching obstacle or moving away from it (if past)
            // This can help differentiate states when player is past the obstacle.
            const playerVelXSign = Math.sign(PLAYER_MOVE_SPEED); // Assuming constant forward speed when moving.

            return `${horizontalPosCategory}_${verticalPosCategory}_${player.onGround}_${playerVelXSign}`;
        }

        // --- Helper: Choose Action (Epsilon-Greedy) ---
        function chooseAction(state) {
            if (!qTable[state]) {
                qTable[state] = Array(ACTIONS.length).fill(0); // Initialize Q-values for new state
            }

            if (Math.random() < epsilon) {
                return Math.floor(Math.random() * ACTIONS.length); // Explore: random action
            } else {
                // Exploit: choose best action
                const qValues = qTable[state];
                return qValues.indexOf(Math.max(...qValues));
            }
        }

        // --- Helper: Update Q-Table ---
        function updateQTable(prevState, action, reward, nextState) {
            if (!qTable[prevState]) { // Should already exist from chooseAction
                qTable[prevState] = Array(ACTIONS.length).fill(0);
            }
            if (!qTable[nextState]) { // Initialize if next state is new
                qTable[nextState] = Array(ACTIONS.length).fill(0);
            }

            const oldQValue = qTable[prevState][action];
            const maxFutureQ = Math.max(...qTable[nextState]);
            const newQValue = oldQValue + LEARNING_RATE * (reward + DISCOUNT_FACTOR * maxFutureQ - oldQValue);
            qTable[prevState][action] = newQValue;
        }

        // --- Game Reset ---
        function resetGame(isSuccess) {
            player.x = 50;
            player.y = GROUND_Y - player.height;
            player.vy = 0;
            player.onGround = true;
            currentSteps = 0;
            episodeCount++;

            // Update stats
            episodeEl.textContent = episodeCount;
            cookiesEl.textContent = cookies;
            punishmentsEl.textContent = punishments;

            // Decay epsilon
            if (epsilon > MIN_EPSILON) {
                epsilon *= EPSILON_DECAY;
            }
            epsilonEl.textContent = epsilon.toFixed(3);
        }

        // --- Collision Detection ---
        function checkCollision(rect1, rect2) {
            return rect1.x < rect2.x + rect2.width &&
                   rect1.x + rect1.width > rect2.x &&
                   rect1.y < rect2.y + rect2.height &&
                   rect1.y + rect1.height > rect2.y;
        }

        // --- Game Update Logic (called by AI loop) ---
        function updateGame(actionIndex) {
            const action = ACTIONS[actionIndex];
            lastActionEl.textContent = action.name;

            let reward = -0.1; // Small penalty for each step to encourage speed

            // Apply actions
            if (action.move) {
                player.x += PLAYER_MOVE_SPEED;
            }
            if (action.jump && player.onGround) {
                player.vy = PLAYER_JUMP_FORCE;
                player.onGround = false;
            }

            // Physics
            player.vy += GRAVITY;
            player.y += player.vy;

            // Ground collision
            if (player.y + player.height >= GROUND_Y) {
                player.y = GROUND_Y - player.height;
                player.vy = 0;
                player.onGround = true;
            }

            // Boundary checks (simple respawn if out of left/right bounds)
            if (player.x + player.width < 0 || player.x > gameCanvas.width) {
                reward = -10; // Severe punishment for going off screen
                punishments++;
                return { reward, done: true };
            }
            
            // Obstacle collision
            if (checkCollision(player, obstacle)) {
                reward = -10; // Punishment for hitting obstacle
                punishments++;
                return { reward, done: true };
            }

            // Goal check
            if (player.x + player.width > GOAL_LINE_X && player.x < GOAL_LINE_X + GOAL_LINE_WIDTH) {
                if (player.y + player.height > obstacle.y) { // Must be on ground or slightly above, not falling from sky
                     reward = 10; // Cookie!
                     cookies++;
                     return { reward, done: true };
                }
            }
            
            // Timeout
            currentSteps++;
            if (currentSteps >= MAX_STEPS_PER_EPISODE) {
                reward = -5; // Punishment for taking too long
                punishments++;
                return { reward, done: true };
            }

            return { reward, done: false };
        }

        // --- Drawing Functions ---
        function drawGame() {
            // Clear canvas
            gameCtx.clearRect(0, 0, gameCanvas.width, gameCanvas.height);

            // Draw ground
            gameCtx.fillStyle = '#70b070'; // Greenish
            gameCtx.fillRect(0, GROUND_Y, gameCanvas.width, gameCanvas.height - GROUND_Y);

            // Draw player
            gameCtx.fillStyle = 'blue';
            gameCtx.fillRect(player.x, player.y, player.width, player.height);

            // Draw obstacle
            gameCtx.fillStyle = 'red';
            gameCtx.fillRect(obstacle.x, obstacle.y, obstacle.width, obstacle.height);

            // Draw goal line
            gameCtx.fillStyle = 'green';
            gameCtx.fillRect(GOAL_LINE_X, 0, GOAL_LINE_WIDTH, gameCanvas.height);
        }

        function drawAiVision() {
            aiVisionCtx.clearRect(0, 0, aiVisionCanvas.width, aiVisionCanvas.height);
            
            const stateStr = getDiscretizedState(); // Use the same state representation
            const parts = stateStr.split('_'); // [horizontalPos, verticalPos, onGround, velXSign]

            const cellWidth = aiVisionCanvas.width / 4; // For horizontal categories
            const cellHeight = aiVisionCanvas.height / 3; // For vertical categories

            // --- Visualize Horizontal Position Category ---
            // 0: Far before, 1: Near before, 2: Under/Over, 3: Past
            const horizCat = parseInt(parts[0]);
            aiVisionCtx.fillStyle = 'rgba(255, 0, 0, 0.3)'; // Red tint for obstacle area approximation
            if (horizCat === 0) aiVisionCtx.fillRect(0, 0, cellWidth, aiVisionCanvas.height);
            else if (horizCat === 1) aiVisionCtx.fillRect(cellWidth, 0, cellWidth, aiVisionCanvas.height);
            else if (horizCat === 2) aiVisionCtx.fillRect(2 * cellWidth, 0, cellWidth, aiVisionCanvas.height);
            else aiVisionCtx.fillRect(3 * cellWidth, 0, cellWidth, aiVisionCanvas.height);

            // --- Visualize Vertical Position Category ---
            // 0: Below, 1: Near/Level, 2: Above (relative to obstacle top)
            const vertCat = parseInt(parts[1]);
            aiVisionCtx.fillStyle = 'rgba(0, 0, 255, 0.3)'; // Blue tint for player height approximation
            if (vertCat === 0) aiVisionCtx.fillRect(0, 2 * cellHeight, aiVisionCanvas.width, cellHeight); // Player is low
            else if (vertCat === 1) aiVisionCtx.fillRect(0, cellHeight, aiVisionCanvas.width, cellHeight); // Player is mid
            else aiVisionCtx.fillRect(0, 0, aiVisionCanvas.width, cellHeight); // Player is high

            // --- Visualize On Ground ---
            const onGround = parts[2] === 'true';
            aiVisionCtx.fillStyle = onGround ? 'rgba(0, 255, 0, 0.5)' : 'rgba(255, 255, 0, 0.5)'; // Green if on ground, Yellow if in air
            aiVisionCtx.fillRect(aiVisionCanvas.width - 20, aiVisionCanvas.height - 20, 20, 20); // Small indicator box

            // Draw grid lines for clarity
            aiVisionCtx.strokeStyle = '#aaa';
            aiVisionCtx.lineWidth = 1;
            for (let i = 1; i < 4; i++) { // Horizontal lines
                aiVisionCtx.beginPath();
                aiVisionCtx.moveTo(i * cellWidth, 0);
                aiVisionCtx.lineTo(i * cellWidth, aiVisionCanvas.height);
                aiVisionCtx.stroke();
            }
            for (let i = 1; i < 3; i++) { // Vertical lines
                aiVisionCtx.beginPath();
                aiVisionCtx.moveTo(0, i * cellHeight);
                aiVisionCtx.lineTo(aiVisionCanvas.width, i * cellHeight);
                aiVisionCtx.stroke();
            }

            // Simple text of state
            aiVisionCtx.fillStyle = 'black';
            aiVisionCtx.font = '10px Arial';
            aiVisionCtx.textAlign = 'center';
            aiVisionCtx.fillText(stateStr, aiVisionCanvas.width / 2, aiVisionCanvas.height - 5);
        }


        // --- Main AI Loop ---
        let previousState = null;
        let previousAction = null;

        function aiLoop() {
            const currentState = getDiscretizedState();
            
            // If there was a previous state, update Q-table based on the outcome of that action
            // This is deferred because we need the 'reward' and 'nextState' (which is 'currentState' now)
            if (previousState !== null && previousAction !== null) {
                // The reward calculation happens in updateGame, which was called in the *previous* iteration
                // So, the 'gameOutcome.reward' we got before is the reward for 'previousState' and 'previousAction'
                // This is a bit tricky: we update based on the *result* of the *previous* action.
                // For the very first step of an episode, previousState will be null.
                // The 'reward' is associated with transitioning FROM previousState TO currentState.
                // Let's re-think: The updateQTable should happen AFTER an action is taken and outcome observed.
            }

            const actionToTake = chooseAction(currentState);
            const gameOutcome = updateGame(actionToTake); // This applies the action and returns reward & done status

            const nextStateAfterAction = getDiscretizedState(); // State after action is taken

            // Now update Q-table with (currentState, actionToTake, gameOutcome.reward, nextStateAfterAction)
            updateQTable(currentState, actionToTake, gameOutcome.reward, nextStateAfterAction);

            // Drawing
            drawGame();
            drawAiVision();

            if (gameOutcome.done) {
                resetGame(gameOutcome.reward > 0); // Pass if it was a success (cookie)
                previousState = null; // Reset for new episode
                previousAction = null;
            } else {
                previousState = currentState; // Store for next iteration's Q-update (though we update immediately now)
                previousAction = actionToTake;
            }
        }

        // --- Initialize and Start ---
        function init() {
            alphaEl.textContent = LEARNING_RATE;
            gammaEl.textContent = DISCOUNT_FACTOR;
            resetGame(false); // Initial reset
            drawGame();
            drawAiVision();
            setInterval(aiLoop, 200); // Slow down for visualization (200ms per step)
        }

        window.onload = init;
    </script>
</body>
</html>
